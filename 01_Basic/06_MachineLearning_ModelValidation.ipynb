{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_MachineLearning_ModelValidation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcNWqnGYaLDtUT9YINR73q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoGoncRibeiro/06_MachineLearning/blob/main/01_Basic/06_MachineLearning_ModelValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning: Model validation\n",
        "\n",
        "In this course, we will learn more about how can we validate our models, so that they can reliably be used in production. Usually, when we build and train our models, we separate two data sets: training and test sets. However, usually, we use the test set to decide which model to use. This means that we actually are fitting our model to the test set, but we still have to guarantee that the accuracy shown in the test (and training) set can be expected in a real world environment. Thus, we should use appropriate techniques to **validate** our model. \n",
        "\n",
        "In this course, we will use the following packages:"
      ],
      "metadata": {
        "id": "5QP8781-FVOp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "r_fNwmw8FF-z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, we will use the following dataset:"
      ],
      "metadata": {
        "id": "u-fDh3HAGkV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
        "df = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
        "df.columns = ['Price', 'Sold', 'Age', 'Km_per_year']\n",
        "df.head( )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DMc8mNouGjoi",
        "outputId": "fd575c7b-407a-4508-f226-d912798910f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Price  Sold  Age  Km_per_year\n",
              "0   30941.02     1   18  35085.22134\n",
              "1   40557.96     1   20  12622.05362\n",
              "2   89627.50     0   12  11440.79806\n",
              "3   95276.14     0    3  43167.32682\n",
              "4  117384.68     1    4  12770.11290"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c33a6aa-e740-4c30-9be7-1dbba4fcb525\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Sold</th>\n",
              "      <th>Age</th>\n",
              "      <th>Km_per_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30941.02</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>35085.22134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40557.96</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>12622.05362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>89627.50</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11440.79806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95276.14</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>43167.32682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117384.68</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12770.11290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c33a6aa-e740-4c30-9be7-1dbba4fcb525')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c33a6aa-e740-4c30-9be7-1dbba4fcb525 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c33a6aa-e740-4c30-9be7-1dbba4fcb525');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is related to different cars, with their selling prices, age, and km per year. Also, we can see whether they were sold or not. "
      ],
      "metadata": {
        "id": "eA2nzNJ9GtK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a baseline model\n",
        "\n",
        "Here, we will already create a baseline model to compare to others later. First, we will split our dataset into training and test sets, then we fit a model. Here, we will start with a dummy classifier model. "
      ],
      "metadata": {
        "id": "JSv_pzGbHTOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 158020\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Train test split\n",
        "y = df.Sold\n",
        "X = df.drop('Sold', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y)\n",
        "\n",
        "# Model fitting\n",
        "dummy_clf = DummyClassifier( )\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "y_pred = dummy_clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)*100\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9u3x3spGrx6",
        "outputId": "cbf6d809-829a-4f48-f59d-336107f1a324"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, a Dummy Classifier model showed an accuracy of 58%. What about a decision tree model?"
      ],
      "metadata": {
        "id": "dWSM_fOKLR1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 158020\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Train test split\n",
        "y = df.Sold\n",
        "X = df.drop('Sold', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y)\n",
        "\n",
        "# Model fitting\n",
        "dec_tree = DecisionTreeClassifier(max_depth = 2)\n",
        "dec_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "y_pred = dec_tree.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)*100\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXWwohinI4Pu",
        "outputId": "b7e71e44-3657-4eff-d3e8-148763e7e03c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 71.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A decision tree model showed a much higher accuracy. \n",
        "\n",
        "Note that this accuracy is very dependent on the seed used. For instance, if we change the seed to 5:"
      ],
      "metadata": {
        "id": "GLukQ2-uLpgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Train test split\n",
        "y = df.Sold\n",
        "X = df.drop('Sold', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y)\n",
        "\n",
        "# Model fitting\n",
        "dec_tree = DecisionTreeClassifier(max_depth = 2)\n",
        "dec_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "y_pred = dec_tree.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)*100\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oTBYXzZLoGf",
        "outputId": "e057b7b1-d888-40ce-8110-6c4b1b479a35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 76.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A much higher accuracy! However, shouldn't we have a more safe way to evaluate the accuracy of our model? How can we say that, in production, we expect our model to present an accuracy of $x\\%$?\n",
        "\n",
        "To that end, we should try to use appropriate methods to evaluate the accuracy over a given set."
      ],
      "metadata": {
        "id": "q_WFECU0L_QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation\n",
        "\n",
        "When we split our data into train and test sets, we effectively separate our data. This means that:\n",
        "\n",
        "* We lose some data that could be used for training.\n",
        "* Our accuracy is entirely dependent on the test set chosen.\n",
        "\n",
        "However, we could try to use another approach: cross-validation. Using cross-validation, we perform multiple splits, and keep training and testing with different sets. This way, we may use the entire dataset for training purposes, while also having a good estimate of how accurate is our model. This time, the accuracy of our model can be given by the mean of the accuracy of all splits!\n",
        "\n",
        "This idea is known as $k$-fold cross-validation, where $k$ is the number of splits in our data."
      ],
      "metadata": {
        "id": "jb41zSItM3P5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, let's try to use the cross-validation to get the accuracy for our Decision Tree Classifier:"
      ],
      "metadata": {
        "id": "AjTIt-YZOstr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 158020\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Defining the target and explicative variables\n",
        "y = df.Sold\n",
        "X = df.drop('Sold', axis = 1)\n",
        "\n",
        "# Model instancing\n",
        "dec_tree = DecisionTreeClassifier(max_depth = 2)\n",
        "\n",
        "# Running cross_validation\n",
        "results = cross_validate(dec_tree, X, y, cv = 3)           # 3-fold cross-validation\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgOIfmIZL-n3",
        "outputId": "2740c9ea-c366-4fab-df8d-6ef9cd8e2191"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.00810766, 0.00716019, 0.00715661]),\n",
              " 'score_time': array([0.00218606, 0.0020206 , 0.00208902]),\n",
              " 'test_score': array([0.75704859, 0.7629763 , 0.75337534])}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here, we are mostly worried with the ```test_score```. Let's get the mean test score:"
      ],
      "metadata": {
        "id": "YCaDlafEPd6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating model accuracy\n",
        "acc = (results['test_score'].mean( ))*100\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oczLigiWPbTb",
        "outputId": "98ec274d-5b6d-4900-c86f-d693a26e2bb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, on average, using 3-fold cross-validation, our model showed an accuracy of 75.78% (across the 3 splits).\n",
        "\n",
        "Also, since we have multiple values, and we have an uncertainty, we can also get a confidence interval for the accuracy. For a significance of 5%, we can consider that $Z \\approx 2.0$. Thus, we can do:"
      ],
      "metadata": {
        "id": "EQv341mtPy0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = (results['test_score'].mean( ))*100\n",
        "std = (results['test_score'].std( ))*100\n",
        "\n",
        "print(\"Accuracy is in the domain [{:.2f}%, {:.2f}%]\".format(acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRIV_jWUPu-Q",
        "outputId": "d8726009-afe2-4291-c4eb-eb3d6182059d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is in the domain [74.99%, 76.57%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Now, we have a confidence interval for our accuracy. Now, we are much less prone to being biased towards \"luck\", as the SEED has a lower effect on the accuracy! For instance, let's use a different seed:"
      ],
      "metadata": {
        "id": "UHIJUbboQp6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Defining the target and explicative variables\n",
        "y = df.Sold\n",
        "X = df.drop('Sold', axis = 1)\n",
        "\n",
        "# Model instancing\n",
        "dec_tree = DecisionTreeClassifier(max_depth = 2)\n",
        "\n",
        "# Running cross_validation\n",
        "results = cross_validate(dec_tree, X, y, cv = 3)           # 3-fold cross-validation\n",
        "\n",
        "# Evaluating model accuracy\n",
        "acc = (results['test_score'].mean( ))*100\n",
        "std = (results['test_score'].std( ))*100\n",
        "\n",
        "print(\"Accuracy is in the domain [{:.2f}%, {:.2f}%]\".format(acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8JlnRN4QlRX",
        "outputId": "9f3e4f26-5946-4712-91ad-8cd4224996d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is in the domain [74.99%, 76.57%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, we got the same domain! That is very good. However, note that 3-folds might be still very little to get a good estimate for the accuracy. After all, we are evaluating a confidence interval using only 3 values. Let's use 10-folds:"
      ],
      "metadata": {
        "id": "0n4t4pBZREBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 158020\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Defining the target and explicative variables\n",
        "y = df.Sold\n",
        "X = df.drop('Sold', axis = 1)\n",
        "\n",
        "# Model instancing\n",
        "dec_tree = DecisionTreeClassifier(max_depth = 2)\n",
        "\n",
        "# Running cross_validation\n",
        "results = cross_validate(dec_tree, X, y, cv = 10)           # 10-fold cross-validation\n",
        "\n",
        "# Evaluating model accuracy\n",
        "acc = (results['test_score'].mean( ))*100\n",
        "std = (results['test_score'].std( ))*100\n",
        "\n",
        "print(\"Accuracy is in the domain [{:.2f}%, {:.2f}%]\".format(acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mab1vElQRCMD",
        "outputId": "4c57a333-aad7-4252-a31b-e6809548e445"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is in the domain [74.24%, 77.32%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that our interval changed, even though it still stayed pretty close to before. \n",
        "\n",
        "Usually, 5 or 10 is a good choice for $k$."
      ],
      "metadata": {
        "id": "iiqyyD4zRWxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Considering randomness in the cross-validation\n",
        "\n",
        "Note that, using the sci-kit learn implementation of cross-validate, the method does not shuffle the dataset before spliting it into multiple folds. To consider randomness in the process, which could give us more certainty about our accuracy domain, we could try to shuffle the dataset before performing the cross-validation. \n",
        "\n",
        "Before doing that, let's create an user-defined function, so that we don't have to repeat multiple lines of code:"
      ],
      "metadata": {
        "id": "ichZaCNiSBCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetCrossValidationMetrics(model, X, y, cv):\n",
        "  results = cross_validate(model, X, y, cv = cv)  \n",
        "\n",
        "  acc = (results['test_score'].mean( ))*100\n",
        "  std = (results['test_score'].std( ))*100  \n",
        "\n",
        "  return (acc, std)  "
      ],
      "metadata": {
        "id": "-xgTl6tGS8Tx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our function:"
      ],
      "metadata": {
        "id": "TDY5SVQWTZ23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a seed\n",
        "SEED = 158020\n",
        "np.random.seed(SEED)\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(dec_tree, X, y, 10)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7bE0L4SRVSL",
        "outputId": "128e583c-bb48-4def-d60f-577db7dd8e96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 75.78%, and it is in the domain [74.24%, 77.32%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We got the same results. Now, to shuffle our folds, we should use a KFold object, and pass it as our cross-validation method:"
      ],
      "metadata": {
        "id": "jY1i4zdyTdWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 158020\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = KFold(n_splits = 10, shuffle = True)\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(dec_tree, X, y, cv)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIf59cMjTXkt",
        "outputId": "c3490839-eedf-41a3-e033-e92b17740d1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 75.78%, and it is in the domain [73.58%, 77.98%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we got different domains (even though our accuracy was actually the same). Let's test another seed:"
      ],
      "metadata": {
        "id": "DtN5zKn_UGXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = KFold(n_splits = 10, shuffle = True)\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(dec_tree, X, y, cv)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVwS2tkT-mk",
        "outputId": "8e4f241a-950a-4837-db23-ad7b0e036e27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 75.76%, and it is in the domain [73.26%, 78.26%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, the accuracy was very similar, but the domain was different!\n",
        "\n",
        "Note that, by using a cross-validation technique, we are less susceptible to randomness, as our accuracy changes very little for different seeds. At the same time, we can still note a difference in the domains!"
      ],
      "metadata": {
        "id": "QaEl1YpQUQXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratifying our dataset in our cross-validation\n",
        "\n",
        "When we split our data into multiple folds, another good practice is that we try to maintain the stratification of the original dataset. For instance, if our target labels has 20% 0's and 80% 1's, we want to keep this proportion in our splits. \n",
        "\n",
        "Using the train test split, we used the ```stratify``` parameter. However, for the KFold, we do not have such a parameter. \n",
        "\n",
        "For that end, we may use the StratifiedKFold method:"
      ],
      "metadata": {
        "id": "otYYDT6oox9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = StratifiedKFold(n_splits = 10, shuffle = True)\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(dec_tree, X, y, cv)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "id": "_LydIl-hUPHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7d696b-3c90-42c9-e61a-5cc697f6da0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 75.78%, and it is in the domain [74.42%, 77.14%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Note that our accuracy changed very little, but our interval is smaller. That occurs because our variance for our splits reduced! That is expected, since, now, we are forcing that our splits have a similar structure (which is similar to the structure from the original set)."
      ],
      "metadata": {
        "id": "9G_FtWEhqjtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping by a feature\n",
        "\n",
        "What if we want to perform our splits based on a feature? As if we split our entries based on the model of the car. This time, we have a different cross-validation method.\n",
        "\n",
        "First, let's generate our car model data (randomly):"
      ],
      "metadata": {
        "id": "Uh3VWpNM7doC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED)\n",
        "\n",
        "df['Model'] = df.Age + np.random.randint(-2, 3, size = df.shape[0])\n",
        "df.Model = df.Model - df.Model.min( ) + 1"
      ],
      "metadata": {
        "id": "HWW9srvpqh9k"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, to consider the model type when performing our splits, we simply use GroupKFold. First, we have to change our user defined function to get the group:"
      ],
      "metadata": {
        "id": "BfljJuxP9OT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetCrossValidationMetrics(model, X, y, cv, group = None):\n",
        "  results = cross_validate(model, X, y, cv = cv, groups = group)  \n",
        "\n",
        "  acc = (results['test_score'].mean( ))*100\n",
        "  std = (results['test_score'].std( ))*100  \n",
        "\n",
        "  return (acc, std)"
      ],
      "metadata": {
        "id": "sAKmOPyi-Krr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can do:"
      ],
      "metadata": {
        "id": "uLvVNOW4-P8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(dec_tree, X, y, cv, df.Model)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sctP3Q5n8sGz",
        "outputId": "e3d384d5-64b2-4c7c-bfe7-af92c1ac9cc8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 75.80%, and it is in the domain [72.00%, 79.60%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Again, our accuracy was very similar. However, in real world problems, this approach may given a much better accuracy, especially when we want to know the expected accuracy for a new car model."
      ],
      "metadata": {
        "id": "6HfezEZ7-ZOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation pipeline\n",
        "\n",
        "It is important that we have a cross-validation pipeline, which allow us to test different models and approaches with our cross-validation methods very easily. \n",
        "\n",
        "Our user-defined function helps with this. However, a model pipeline should have even more functionalities. In the following, I show a more complete pipeline for model training and validating:"
      ],
      "metadata": {
        "id": "7F3O3jip_CeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetCrossValidationMetrics(scaler, model, X, y, cv, group = None):\n",
        "  # Feature normalization\n",
        "  scaler.fit(X)\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "  # Cross-validation\n",
        "  results = cross_validate(model, X_scaled, y, cv = cv, groups = group) \n",
        "\n",
        "  # Get accuracy\n",
        "  acc = (results['test_score'].mean( ))*100\n",
        "  std = (results['test_score'].std( ))*100  \n",
        "\n",
        "  return (acc, std)"
      ],
      "metadata": {
        "id": "plCaImNk-Sa8"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Now, let's test it:"
      ],
      "metadata": {
        "id": "IVIp5nVVA3Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = StratifiedKFold(n_splits = 10, shuffle = True)\n",
        "scaler = StandardScaler( )\n",
        "model = SVC( )\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(scaler, model, X, y, cv)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33-m7laU_56O",
        "outputId": "ae827d44-38d4-441c-8f5b-77e90255746e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 76.71%, and it is in the domain [74.21%, 79.21%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! However, we could also create a pipeline using the ```Pipeline``` object, implemented by the sklearn documentation. Thus, we may simply do:"
      ],
      "metadata": {
        "id": "jveoQnnzCLN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler( )\n",
        "model  = SVC( )\n",
        "\n",
        "pipeline = Pipeline([('scaling', scaler), ('estimator', model)])"
      ],
      "metadata": {
        "id": "oTTqILX1BE8A"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we create a pipeline, we can use cross-validation in the pipeline:"
      ],
      "metadata": {
        "id": "zuhKJUvwDDpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetCrossValidationMetrics(pipeline, X, y, cv, group = None):\n",
        "  # Cross-validation\n",
        "  results = cross_validate(pipeline, X, y, cv = cv, groups = group) \n",
        "\n",
        "  # Get accuracy\n",
        "  acc = (results['test_score'].mean( ))*100\n",
        "  std = (results['test_score'].std( ))*100  \n",
        "\n",
        "  return (acc, std)"
      ],
      "metadata": {
        "id": "RlGgCJk1Cxas"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = StratifiedKFold(n_splits = 10, shuffle = True)\n",
        "\n",
        "acc, std = GetCrossValidationMetrics(pipeline, X, y, cv)\n",
        "\n",
        "print(\"Accuracy is {:.2f}%, and it is in the domain [{:.2f}%, {:.2f}%]\".format(acc, acc - 2*std, acc + 2*std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkjxAN5-DRlX",
        "outputId": "72cb5967-9547-42d8-b8b1-f4885631adce"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 76.72%, and it is in the domain [74.18%, 79.26%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Our pipeline worked."
      ],
      "metadata": {
        "id": "5tdKln0aDlzx"
      }
    }
  ]
}